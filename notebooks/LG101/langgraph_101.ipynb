{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6e5cee",
   "metadata": {},
   "source": [
    "# LangGraph 101: Building Your First Agent (TypeScript)\n",
    "\n",
    "Welcome to LangGraph 101! This notebook will walk you through the core concepts of building agents with LangChain and LangGraph using TypeScript.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to interact with language models\n",
    "- Working with messages and conversation\n",
    "- Adding tools to extend LLM capabilities\n",
    "- Building an agent that can reason and act\n",
    "- Adding memory to maintain context\n",
    "- Streaming responses for better UX\n",
    "<br>\n",
    "<br>\n",
    "---\n",
    "<br>\n",
    "\n",
    "> **Note:** This tutorial uses LangChain v1, which provides the easiest way to start building with LLMs. LangChain agents are built on top of LangGraph, providing durable execution, streaming, human-in-the-loop, and persistence out of the box.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8668a",
   "metadata": {},
   "source": [
    "## Part 0: Setup & Installation\n",
    "\n",
    "First, let's install the necessary packages and set up our environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "// Install required packages (run in terminal):\n",
    "// pnpm add langchain @langchain/core @langchain/langgraph @langchain/openai zod uuid dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa1d1a",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "// Load environment variables\n",
    "import \"dotenv/config\";\n",
    "\n",
    "// We'll use OpenAI in this tutorial, but you can swap to any provider!\n",
    "// Supported providers: OpenAI, Anthropic, Google, and many more\n",
    "\n",
    "console.log(\"Environment loaded successfully!\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d6f6c",
   "metadata": {},
   "source": [
    "## Part 1: Your First LLM Call\n",
    "\n",
    "LangChain provides a **standard model interface** that works across all providers. This means you can easily swap between OpenAI, Anthropic, Google, and other providers without changing your code.\n",
    "\n",
    "Let's start by initializing a chat model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74208dc3",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { initChatModel } from \"langchain\";\n",
    "\n",
    "// Initialize a chat model - you can easily swap providers!\n",
    "// Examples: \"openai:gpt-4o\", \"anthropic:claude-3-7-sonnet-latest\", \"google:gemini-2.0-flash\"\n",
    "const model = await initChatModel(\"openai:gpt-4o-mini\");\n",
    "\n",
    "// Make your first call!\n",
    "const response = await model.invoke(\"What is LangChain?\");\n",
    "console.log(response.content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf76ee",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `initChatModel()` gives you a standardized interface to any LLM provider\n",
    "- `.invoke()` sends a message and returns a response\n",
    "- No provider lock-in - swap models easily!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850a575",
   "metadata": {},
   "source": [
    "## Part 2: Understanding Messages\n",
    "\n",
    "**Messages** are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both content and metadata.\n",
    "\n",
    "There are different message types:\n",
    "- **SystemMessage** - Instructions for how the model should behave\n",
    "- **HumanMessage** - User input\n",
    "- **AIMessage** - Model responses\n",
    "- **ToolMessage** - Results from tool executions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48d1c0",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { HumanMessage, SystemMessage } from \"langchain\";\n",
    "\n",
    "// Create a conversation with different message types\n",
    "const messages = [\n",
    "    new SystemMessage(\"You are a helpful AI assistant that explains technical concepts simply.\"),\n",
    "    new HumanMessage(\"What is an agent?\"),\n",
    "];\n",
    "\n",
    "const response2 = await model.invoke(messages);\n",
    "console.log(response2.content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2115b2d",
   "metadata": {},
   "source": [
    "### Multi-turn Conversations\n",
    "\n",
    "Messages make it easy to maintain conversation history:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40774d",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "// Continue the conversation\n",
    "messages.push(response2);  // Add AI response to history\n",
    "messages.push(new HumanMessage(\"Can you give me an example?\"));\n",
    "\n",
    "const response3 = await model.invoke(messages);\n",
    "console.log(response3.content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5d969",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Messages represent the conversation history\n",
    "- SystemMessage sets the model's behavior\n",
    "- Build multi-turn conversations by appending messages to an array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d7140",
   "metadata": {},
   "source": [
    "## Part 3: Adding Tools - Extending LLM Capabilities\n",
    "\n",
    "LLMs are great at language, but they can't access external data or perform actions. **Tools** extend their capabilities. You can give an LLM a list of tools, and when it needs one, it will specify which tool to call. Your job is to execute the tool and feed the results back to the LLM so it can decide what to do next.\n",
    "\n",
    "You can create a tool just by writing a function with a clear description. LangChain's `tool` function handles formatting the function's information in the LLM's desired format.\n",
    "\n",
    "Let's create some simple tools:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7e60b",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { tool } from \"langchain\";\n",
    "import { z } from \"zod\";\n",
    "\n",
    "// Basic hardcoded tool\n",
    "const searchMovies = tool(\n",
    "  async ({ genre }: { genre: string }) => {\n",
    "    // In a real app, this would query a movie database\n",
    "    const movies: Record<string, string> = {\n",
    "      \"sci-fi\": \"Dune, Interstellar, Blade Runner 2049\",\n",
    "      \"comedy\": \"The Grand Budapest Hotel, Superbad, Knives Out\",\n",
    "      \"action\": \"Mad Max: Fury Road, John Wick, Mission Impossible\"\n",
    "    };\n",
    "    return movies[genre.toLowerCase()] || \"No movies found for that genre\";\n",
    "  },\n",
    "  {\n",
    "    name: \"search_movies\",\n",
    "    description: \"Search for movies by genre.\",\n",
    "    schema: z.object({\n",
    "      genre: z.string().describe(\"The genre of movies to search for\")\n",
    "    })\n",
    "  }\n",
    ");\n",
    "\n",
    "// More realistic tool that calls an API\n",
    "const getWeather = tool(\n",
    "  async ({ latitude, longitude }: { latitude: number; longitude: number }) => {\n",
    "    const url = \"https://api.open-meteo.com/v1/forecast\";\n",
    "    const params = new URLSearchParams({\n",
    "      latitude: latitude.toString(),\n",
    "      longitude: longitude.toString(),\n",
    "      current: \"temperature_2m,weather_code\",\n",
    "      temperature_unit: \"fahrenheit\"\n",
    "    });\n",
    "\n",
    "    const response = await fetch(`${url}?${params}`);\n",
    "    const data = await response.json();\n",
    "    const weather = data.current;\n",
    "    const temperature = weather.temperature_2m;\n",
    "    const weatherCode = weather.weather_code;\n",
    "    \n",
    "    return JSON.stringify({\n",
    "      temperature_fahrenheit: temperature,\n",
    "      weather_code: weatherCode\n",
    "    });\n",
    "  },\n",
    "  {\n",
    "    name: \"get_weather\",\n",
    "    description: \"Get current temperature in Fahrenheit and weather code for given coordinates. Returns JSON with temperature_fahrenheit and weather_code (do not include the code in your response, translate it to plain English)\",\n",
    "    schema: z.object({\n",
    "      latitude: z.number().describe(\"Latitude coordinate\"),\n",
    "      longitude: z.number().describe(\"Longitude coordinate\")\n",
    "    })\n",
    "  }\n",
    ");\n",
    "\n",
    "// Test a tool directly with SF's coordinates\n",
    "console.log(await getWeather.invoke({ latitude: 37.77, longitude: -122.42 }));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea91175",
   "metadata": {},
   "source": [
    "### Tool Calling (Function Calling)\n",
    "\n",
    "Now let's give these tools to the model using `.bindTools()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775f568",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "// Bind tools to the model\n",
    "const tools = [getWeather, searchMovies];\n",
    "const modelWithTools = model.bindTools(tools);\n",
    "const message = \"What's the weather like in Seattle?\";\n",
    "\n",
    "// The model can now decide to call tools\n",
    "const response4 = await modelWithTools.invoke(message);\n",
    "\n",
    "// Check if the model wants to call a tool\n",
    "console.log(\"Tool calls:\", response4.tool_calls);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f4a35",
   "metadata": {},
   "source": [
    "The model returns a **tool call** request with:\n",
    "- `name`: Which tool to call\n",
    "- `args`: Arguments to pass to the tool\n",
    "- `id`: Unique identifier for tracking\n",
    "\n",
    "Let's execute the tool and continue the conversation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed4e58",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { ToolMessage } from \"langchain\";\n",
    "\n",
    "// Execute the tool call\n",
    "if (response4.tool_calls && response4.tool_calls.length > 0) {\n",
    "    const toolCall = response4.tool_calls[0];\n",
    "    \n",
    "    // Call the actual tool\n",
    "    let result;\n",
    "    if (toolCall.name === \"get_weather\") {\n",
    "        result = await getWeather.invoke(toolCall.args);\n",
    "    } else if (toolCall.name === \"search_movies\") {\n",
    "        result = await searchMovies.invoke(toolCall.args);\n",
    "    }\n",
    "    \n",
    "    // Create a ToolMessage with the result\n",
    "    const toolMessage = new ToolMessage({\n",
    "        content: result,\n",
    "        tool_call_id: toolCall.id\n",
    "    });\n",
    "    \n",
    "    // Continue the conversation with the tool result\n",
    "    const finalResponse = await modelWithTools.invoke([\n",
    "        new HumanMessage(message),\n",
    "        response4,\n",
    "        toolMessage\n",
    "    ]);\n",
    "    \n",
    "    console.log(finalResponse.content);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373878d",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Tools are functions wrapped with the `tool()` function\n",
    "- Good descriptions help the model know when to use each tool\n",
    "- Tool calling flow: Model requests tool â†’ Execute tool â†’ Return result â†’ Model synthesizes final response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac22108",
   "metadata": {},
   "source": [
    "## Part 4: Building Your First Agent with `createAgent()`\n",
    "\n",
    "Manually defining a specific sequence of LLM calls and tool calls is tedious and inflexible. Instead, we can use an **agent** that runs this loop:\n",
    "1. Model decides which tool to call (if any)\n",
    "2. Tool gets executed\n",
    "3. Result goes back to model\n",
    "4. Repeat until task is complete\n",
    "\n",
    "LangChain makes this easy with `createAgent()` - **build an agent in ~10 lines of code!**\n",
    "The prebuilt agent handles running the loop described above - you just specify the system prompt and tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9de82d",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { createAgent } from \"langchain\";\n",
    "\n",
    "// Create an agent with tools\n",
    "const agent = createAgent({\n",
    "    model: \"openai:gpt-4o-mini\",\n",
    "    tools: [getWeather, searchMovies],\n",
    "    systemPrompt: \"You are a helpful assistant that can check weather and recommend movies.\"\n",
    "});\n",
    "\n",
    "// Use the agent\n",
    "const result = await agent.invoke({\n",
    "    messages: [{ role: \"user\", content: \"What's the weather in NYC? Also recommend some sci-fi movies.\" }]\n",
    "});\n",
    "\n",
    "// Print the conversation\n",
    "for (const msg of result.messages) {\n",
    "    console.log(`[${msg._getType()}]:`, msg.content);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ed05b",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "The agent automatically:\n",
    "1. Analyzed the user's request\n",
    "2. Called `get_weather` for NYC\n",
    "3. Called `search_movies` for \"sci-fi\"\n",
    "4. Synthesized the results into a natural response\n",
    "\n",
    "You can visualize the agent's structure (note: visualization requires additional setup):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93949b36",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `createAgent()` builds a complete agent in ~10 lines\n",
    "- The agent automatically handles the reasoning â†’ action â†’ observation loop\n",
    "- Built on LangGraph for production features (persistence, streaming, human-in-the-loop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac60248",
   "metadata": {},
   "source": [
    "## Part 5: Adding Memory & State\n",
    "\n",
    "Right now, each agent invocation is independent. Let's add **memory** so the agent can maintain context across multiple interactions.\n",
    "\n",
    "LangGraph uses **checkpointers** to save and restore state:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b0a8a",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "import { MemorySaver } from \"@langchain/langgraph\";\n",
    "import { v4 as uuidv4 } from \"uuid\";\n",
    "\n",
    "// Create a checkpointer for memory\n",
    "const checkpointer = new MemorySaver();\n",
    "\n",
    "// Create an agent with memory\n",
    "const agentWithMemory = createAgent({\n",
    "    model: \"openai:gpt-4o-mini\",\n",
    "    tools: [getWeather, searchMovies],\n",
    "    systemPrompt: \"You are a helpful assistant.\",\n",
    "    checkpointer: checkpointer\n",
    "});\n",
    "\n",
    "// Create a thread for this conversation\n",
    "const threadId = uuidv4();\n",
    "const config = { configurable: { thread_id: threadId } };\n",
    "\n",
    "// First interaction\n",
    "const result1 = await agentWithMemory.invoke(\n",
    "    { messages: [{ role: \"user\", content: \"My name is Alice and I love sci-fi movies.\" }] },\n",
    "    config\n",
    ");\n",
    "\n",
    "console.log(\"Response 1:\", result1.messages[result1.messages.length - 1].content);\n",
    "\n",
    "// Second interaction - the agent remembers!\n",
    "const result2 = await agentWithMemory.invoke(\n",
    "    { messages: [{ role: \"user\", content: \"What's my name and what movies do I like?\" }] },\n",
    "    config\n",
    ");\n",
    "console.log(\"\\nResponse 2:\", result2.messages[result2.messages.length - 1].content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d2c9c",
   "metadata": {},
   "source": [
    "### Understanding State & Threads\n",
    "\n",
    "- **State**: The agent's \"memory\" - includes message history and any custom data\n",
    "- **Thread**: A conversation session identified by `thread_id`\n",
    "- **Checkpointer**: Saves state after each step, enabling memory and error recovery\n",
    "\n",
    "Each thread is independent:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2469fa0",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "// New thread - agent won't remember Alice\n",
    "const newThreadId = uuidv4();\n",
    "const newConfig = { configurable: { thread_id: newThreadId } };\n",
    "\n",
    "const result3 = await agentWithMemory.invoke(\n",
    "    { messages: [{ role: \"user\", content: \"What's my name?\" }] },\n",
    "    newConfig\n",
    ");\n",
    "console.log(\"New thread response:\", result3.messages[result3.messages.length - 1].content);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0622cc5",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Checkpointers enable memory across interactions\n",
    "- Thread IDs separate different conversations\n",
    "- State persists automatically - no manual state management needed!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519b4d5",
   "metadata": {},
   "source": [
    "## Part 6: Streaming for Better UX\n",
    "\n",
    "LLMs can take a while to respond. **Streaming** shows progress in real-time, dramatically improving user experience.\n",
    "\n",
    "LangChain supports multiple streaming modes:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ad592",
   "metadata": {},
   "source": [
    "### Streaming Agent Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead9eea",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "// Stream agent progress with streamMode=\"updates\"\n",
    "console.log(\"Streaming agent steps:\\n\");\n",
    "\n",
    "for await (const chunk of await agent.stream(\n",
    "    { messages: [{ role: \"user\", content: \"What's the weather in Boston?\" }] },\n",
    "    { streamMode: \"updates\" }\n",
    ")) {\n",
    "    for (const [nodeName, data] of Object.entries(chunk)) {\n",
    "        console.log(`Step: ${nodeName}`);\n",
    "        if (data.messages) {\n",
    "            const message = data.messages[data.messages.length - 1];\n",
    "            if (message.tool_calls && message.tool_calls.length > 0) {\n",
    "                console.log(`   Tool call: ${message.tool_calls[0].name}`);\n",
    "            } else if (message.content) {\n",
    "                const content = message.content.length > 100 \n",
    "                    ? `${message.content.substring(0, 100)}...` \n",
    "                    : message.content;\n",
    "                console.log(`   Content: ${content}`);\n",
    "            }\n",
    "        }\n",
    "        console.log();\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f1fc3",
   "metadata": {},
   "source": [
    "### Streaming LLM Tokens\n",
    "\n",
    "For a ChatGPT-like experience, stream tokens as they're generated:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c04394",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "// Stream tokens with streamMode=\"messages\"\n",
    "console.log(\"Streaming tokens:\\n\");\n",
    "\n",
    "for await (const [token, metadata] of await agent.stream(\n",
    "    { messages: [{ role: \"user\", content: \"Tell me about LangGraph in one sentence.\" }] },\n",
    "    { streamMode: \"messages\" }\n",
    ")) {\n",
    "    // Only print content from the agent node\n",
    "    if (metadata.langgraph_node === \"agent\") {\n",
    "        // Get text from content blocks\n",
    "        if (token.content_blocks) {\n",
    "            for (const block of token.content_blocks) {\n",
    "                if (block.type === \"text\" && block.text) {\n",
    "                    process.stdout.write(block.text);\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "console.log(\"\\n\");  // New line at the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543acd63",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `streamMode: \"updates\"` - See each agent step (useful for debugging)\n",
    "- `streamMode: \"messages\"` - Stream LLM tokens (ChatGPT-like UX)\n",
    "- Streaming is built-in - no extra setup required!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99e4c1",
   "metadata": {},
   "source": [
    "## Part 7: Putting It All Together - A Practical Example\n",
    "\n",
    "Let's build a more realistic agent that combines everything we've learned:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e9aa1",
   "metadata": {
    "vscode": {
     "languageId": "typescript"
    }
   },
   "outputs": [],
   "source": [
    "// Create more realistic tools\n",
    "const getUserPreferences = tool(\n",
    "  async ({ userId }: { userId: string }) => {\n",
    "    // Simulate a user database\n",
    "    const preferences: Record<string, string> = {\n",
    "      \"alice\": \"Loves sci-fi movies, prefers warm weather destinations\",\n",
    "      \"bob\": \"Enjoys comedy films, likes cold climates for travel\"\n",
    "    };\n",
    "    return preferences[userId.toLowerCase()] || \"No preferences found\";\n",
    "  },\n",
    "  {\n",
    "    name: \"get_user_preferences\",\n",
    "    description: \"Get a user's saved preferences.\",\n",
    "    schema: z.object({\n",
    "      userId: z.string().describe(\"The user ID to look up\")\n",
    "    })\n",
    "  }\n",
    ");\n",
    "\n",
    "const bookRecommendation = tool(\n",
    "  async ({ genre, userPreferences }: { genre: string; userPreferences?: string }) => {\n",
    "    const recommendations: Record<string, string> = {\n",
    "      \"sci-fi\": \"Based on your preferences, try: Arrival, Ex Machina, or The Martian\",\n",
    "      \"comedy\": \"Based on your preferences, try: The Big Lebowski, Anchorman, or Bridesmaids\"\n",
    "    };\n",
    "    return recommendations[genre.toLowerCase()] || \"No recommendations available\";\n",
    "  },\n",
    "  {\n",
    "    name: \"book_recommendation\",\n",
    "    description: \"Get personalized movie recommendations based on genre and user preferences.\",\n",
    "    schema: z.object({\n",
    "      genre: z.string().describe(\"The movie genre\"),\n",
    "      userPreferences: z.string().optional().describe(\"Optional user preferences\")\n",
    "    })\n",
    "  }\n",
    ");\n",
    "\n",
    "// Create a helpful assistant agent\n",
    "const assistant = createAgent({\n",
    "    model: \"openai:gpt-4o-mini\",\n",
    "    tools: [getWeather, getUserPreferences, bookRecommendation],\n",
    "    systemPrompt: `You are a helpful personal assistant. \n",
    "    \n",
    "    You can:\n",
    "    - Check weather for any city\n",
    "    - Look up user preferences\n",
    "    - Recommend movies based on preferences\n",
    "    \n",
    "    Always be friendly and personalize your responses based on user preferences.`,\n",
    "    checkpointer: new MemorySaver()\n",
    "});\n",
    "\n",
    "// Demo conversation\n",
    "const demoThreadId = uuidv4();\n",
    "const demoConfig = { configurable: { thread_id: demoThreadId } };\n",
    "\n",
    "console.log(\"=\".repeat(50));\n",
    "console.log(\"PERSONAL ASSISTANT DEMO\");\n",
    "console.log(\"=\".repeat(50) + \"\\n\");\n",
    "\n",
    "// Interaction 1\n",
    "console.log(\"User: Hi, I'm Alice. Can you check my preferences and recommend a movie?\\n\");\n",
    "const demoResult1 = await assistant.invoke(\n",
    "    { messages: [{ role: \"user\", content: \"Hi, I'm Alice. Can you check my preferences and recommend a movie?\" }] },\n",
    "    demoConfig\n",
    ");\n",
    "console.log(`Assistant: ${demoResult1.messages[demoResult1.messages.length - 1].content}\\n`);\n",
    "\n",
    "// Interaction 2\n",
    "console.log(\"User: Also, what's the weather like in San Francisco?\\n\");\n",
    "const demoResult2 = await assistant.invoke(\n",
    "    { messages: [{ role: \"user\", content: \"Also, what's the weather like in San Francisco?\" }] },\n",
    "    demoConfig\n",
    ");\n",
    "console.log(`Assistant: ${demoResult2.messages[demoResult2.messages.length - 1].content}\\n`);\n",
    "\n",
    "console.log(\"=\".repeat(50));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4c440",
   "metadata": {},
   "source": [
    "## Part 8: Next Steps - Exploring LangGraph Primitives\n",
    "\n",
    "We've been using `createAgent()`, which is built on **LangGraph**. LangGraph gives you full control over agent behavior using three core primitives:\n",
    "\n",
    "### Core LangGraph Concepts:\n",
    "\n",
    "1. **State**\n",
    "   - Shared data structure passed between nodes\n",
    "   - Represents the agent's \"memory\"\n",
    "   - Can include messages, custom data, etc.\n",
    "\n",
    "2. **Nodes**\n",
    "   - Functions that process state\n",
    "   - Each node performs a specific task\n",
    "   - Examples: call LLM, execute tool, validate input\n",
    "\n",
    "3. **Edges**\n",
    "   - Define flow between nodes\n",
    "   - Can be normal (always go to next node)\n",
    "   - Or conditional (decide based on logic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b5a9a",
   "metadata": {},
   "source": [
    "### When to use `createAgent()` vs custom LangGraph?\n",
    "\n",
    "**Use `createAgent()` when:**\n",
    "- Building standard ReAct-style agents\n",
    "- You need quick prototyping\n",
    "- Default behavior works for your use case\n",
    "\n",
    "**Use custom LangGraph when:**\n",
    "- You need custom control flow (e.g., approval workflows)\n",
    "- Building multi-agent systems\n",
    "- Implementing human-in-the-loop patterns\n",
    "- Complex state management requirements\n",
    "\n",
    "For more advanced patterns, check out:\n",
    "- [LangGraph Documentation](https://docs.langchain.com/oss/javascript/langgraph/overview)\n",
    "- [LangChain Academy](https://academy.langchain.com/)\n",
    "- The `multi_agent.ipynb` notebook in this repo (LangGraph 201)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bfcb9",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've learned the core concepts of building agents with LangChain and LangGraph:\n",
    "\n",
    "âœ… **Models** - Standardized interface across providers  \n",
    "âœ… **Messages** - Building block of conversations  \n",
    "âœ… **Tools** - Extending LLM capabilities  \n",
    "âœ… **Agents** - Automated reasoning and action loops  \n",
    "âœ… **Memory** - Maintaining context across interactions  \n",
    "âœ… **Streaming** - Real-time user experience  \n",
    "âœ… **LangGraph** - The foundation powering it all\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "1. **Build your own agent** with your specific tools and use case\n",
    "2. **Explore advanced patterns** in the `multi_agent.ipynb` notebook\n",
    "3. **Add debugging** with [LangSmith](https://smith.langchain.com)\n",
    "4. **Deploy to production** using LangGraph's persistence and error recovery\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [LangChain Documentation](https://docs.langchain.com/oss/javascript/langchain/overview)\n",
    "- [LangGraph Documentation](https://docs.langchain.com/oss/javascript/langgraph/overview)\n",
    "- [LangSmith for Debugging](https://smith.langchain.com)\n",
    "- [LangChain Academy](https://academy.langchain.com/)\n",
    "<br>\n",
    "<br>\n",
    "---\n",
    "<br>\n",
    "\n",
    "**Happy building!**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
